{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Online - Twitter Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulalqy/Algoritmos-Troll/blob/main/Online_Twitter_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFjmfnF5ER_F"
      },
      "source": [
        "# Despliegue de modelos para inferencia online\n",
        "\n",
        "En esta primera práctica vamos a aprender cómo desplegar un modelo para realizar inferencias online usando un microservicio. Para ello, utilizaremos Google Cloud Platform (GCP).\n",
        "\n",
        "El objetivo de esta práctica es dado un modelo ya entrenado, construir un microservicio capaz de disponibilizar nuestro modelo a gran escala para peticiones en tiempo real.\n",
        "\n",
        "El modelo lo tendremos almacenado en Google Cloud Storage y generaremos nuestro microservicio usando FastAPI y lo desplegaremos un el servicio Serverless de GCP, Cloud Run.\n",
        "\n",
        "Al terminar esta práctica seremos capaces de crear microservicios de Machine Learning para poner en inferencia online los modelos que deseemos a gran escala.\n",
        "\n",
        "![online_diagram](https://drive.google.com/uc?export=view&id=1aKmkzTqp0hG1VyuUIWSVbxQa7UKYEo9T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm4ap2ciFlu1"
      },
      "source": [
        "# Para empezar... ¿Qué es una API?\n",
        "\n",
        "Para construir aplicaciones que sean escalables e interactivas, es necesario que éstas sean capaces de comunicarse entre ellas. Por tanto, una API (abreviatura de Application Programming Interface) son una serie de reglas que facilitan las comunicaciones entre aplicaciones. Estas aplicaciones pueden ser librerías de Python o servidores web entre otros.\n",
        "\n",
        "Una de las principales ventajas de una API es que el solicitante no necesita saber el funcionamiento interno de la aplicación ni el lenguaje en el que esté desarrollado para poder responder y viceversa. Esto permite que diferentes servicios que usen diferentes tecnologías se comuniquen de una manera estándar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lPC6gNfFuIo"
      },
      "source": [
        "# Introducción a FastAPI\n",
        "\n",
        "[FastAPI](https://fastapi.tiangolo.com/) es un framework web de alto rendimiento para la construcción de APIs en Python 3.6+. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgjlQkgZJZOd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b8cac1f3-7d81-48fd-c7fb-e767358a6305"
      },
      "source": [
        "! pip install fastapi[all] pyngrok streamlit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fastapi[all]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/33/1b643f650688ad368983bbaf3b0658438038ea84d775dd37393d826c3833/fastapi-0.63.0-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.3MB/s \n",
            "\u001b[?25hCollecting pyngrok\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/ba/562dc75ca358bdecd8bfa4cdfbd27f750e7d6e46699d3a51bcaa7feb7f3e/pyngrok-5.0.3.tar.gz (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 6.3MB/s \n",
            "\u001b[?25hCollecting streamlit\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/6c/c03f12bbbd8367152897c3b3269f87b717b3e7b834b44d15aae345727375/streamlit-0.77.0-py2.py3-none-any.whl (7.5MB)\n",
            "\u001b[K     |████████████████████████████████| 7.5MB 15.9MB/s \n",
            "\u001b[?25hCollecting pydantic<2.0.0,>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/a3/0ffdb6c63f45f10d19b8e8b32670b22ed089cafb29732f6bf8ce518821fb/pydantic-1.8.1-cp37-cp37m-manylinux2014_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 35.9MB/s \n",
            "\u001b[?25hCollecting starlette==0.13.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/a4/c9e228d7d47044ce4c83ba002f28ff479e542455f0499198a3f77c94f564/starlette-0.13.6-py3-none-any.whl (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2<3.0.0,>=2.11.2; extra == \"all\" in /usr/local/lib/python3.7/dist-packages (from fastapi[all]) (2.11.3)\n",
            "Collecting python-multipart<0.0.6,>=0.0.5; extra == \"all\"\n",
            "  Downloading https://files.pythonhosted.org/packages/46/40/a933ac570bf7aad12a298fc53458115cc74053474a72fbb8201d7dc06d3d/python-multipart-0.0.5.tar.gz\n",
            "Collecting async_exit_stack<2.0.0,>=1.0.1; extra == \"all\"\n",
            "  Downloading https://files.pythonhosted.org/packages/77/ae/f5baabf02fe19c4015b0417e72e36220fb95ed3e7cf17e8a85004b964709/async_exit_stack-1.0.1-py3-none-any.whl\n",
            "Collecting aiofiles<0.6.0,>=0.5.0; extra == \"all\"\n",
            "  Downloading https://files.pythonhosted.org/packages/f4/2b/078a9771ae4b67e36b0c2a973df845260833a4eb088b81c84b738509b4c4/aiofiles-0.5.0-py3-none-any.whl\n",
            "Requirement already satisfied: itsdangerous<2.0.0,>=1.1.0; extra == \"all\" in /usr/local/lib/python3.7/dist-packages (from fastapi[all]) (1.1.0)\n",
            "Collecting uvicorn[standard]<0.14.0,>=0.12.0; extra == \"all\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/de/953f0289508b1b92debdf0a6822d9b88ffb0c6ad471d709cf639a2c8a176/uvicorn-0.13.4-py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.2MB/s \n",
            "\u001b[?25hCollecting pyyaml<6.0.0,>=5.3.1; extra == \"all\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 19.0MB/s \n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.2.1; extra == \"all\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/58/9be6b38deff2f19b7e1d76fb760732ec0d01b1fcad7a0f44810c0ecb834b/orjson-3.5.0-cp37-cp37m-manylinux2014_x86_64.whl (233kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 40.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: async_generator<2.0.0,>=1.10; extra == \"all\" in /usr/local/lib/python3.7/dist-packages (from fastapi[all]) (1.10)\n",
            "Collecting graphene<3.0.0,>=2.1.8; extra == \"all\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/97/45e743b372f65a619f8d1eb2897efb74fb1b0ffddc731ad37e0aa187ec5c/graphene-2.1.8-py2.py3-none-any.whl (107kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 41.4MB/s \n",
            "\u001b[?25hCollecting email_validator<2.0.0,>=1.1.1; extra == \"all\"\n",
            "  Downloading https://files.pythonhosted.org/packages/58/f0/39459bb868ddb4e96ee3f8b1386deeceb1bf4e53de8c18a4afdf5801f24c/email_validator-1.1.2-py2.py3-none-any.whl\n",
            "Collecting ujson<4.0.0,>=3.0.0; extra == \"all\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/15/f7d7f9d6b7db49f26aa9bcdd84e4714631c4a2bc21d0522c603492927055/ujson-3.2.0-cp37-cp37m-manylinux1_x86_64.whl (179kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 37.5MB/s \n",
            "\u001b[?25hCollecting requests<3.0.0,>=2.24.0; extra == \"all\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 4.4MB/s \n",
            "\u001b[?25hCollecting pydeck>=0.1.dev5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/3f/8f04ae0c22d82ec7bec7fcc03270a142f637e362bbd285f7daeeda24fbef/pydeck-0.6.1-py2.py3-none-any.whl (4.6MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6MB 38.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.8.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.19.5)\n",
            "Collecting validators\n",
            "  Downloading https://files.pythonhosted.org/packages/db/2f/7fed3ee94ad665ad2c1de87f858f10a7785251ff75b4fd47987888d07ef1/validators-0.18.2-py3-none-any.whl\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.1.0)\n",
            "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.1.5)\n",
            "Collecting blinker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/51/e2a9f3b757eb802f61dc1f2b09c8c99f6eb01cf06416c0671253536517b6/blinker-1.4.tar.gz (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 42.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from streamlit) (20.9)\n",
            "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.12.4)\n",
            "Requirement already satisfied: pyarrow; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.0.0)\n",
            "Collecting base58\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/a1/d9f565e9910c09fd325dc638765e8843a19fa696275c16cc08cf3b0a3c25/base58-2.1.0-py3-none-any.whl\n",
            "Collecting gitpython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 40.7MB/s \n",
            "\u001b[?25hCollecting watchdog; platform_system != \"Darwin\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/ba/a36ca5b4e75649a002f06531862467b3eb5c768caa23d6d88b921fe238d8/watchdog-2.0.2-py3-none-manylinux2014_x86_64.whl (74kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.1)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (5.1.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.0.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic<2.0.0,>=1.0.0->fastapi[all]) (3.7.4.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2<3.0.0,>=2.11.2; extra == \"all\"->fastapi[all]) (1.1.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from python-multipart<0.0.6,>=0.0.5; extra == \"all\"->fastapi[all]) (1.15.0)\n",
            "Collecting h11>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/0f/7a0eeea938eaf61074f29fed9717f2010e8d0e0905d36b38d3275a1e4622/h11-0.12.0-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.0MB/s \n",
            "\u001b[?25hCollecting python-dotenv>=0.13; extra == \"standard\"\n",
            "  Downloading https://files.pythonhosted.org/packages/32/2e/e4585559237787966aad0f8fd0fc31df1c4c9eb0e62de458c5b6cde954eb/python_dotenv-0.15.0-py2.py3-none-any.whl\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0; (sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"PyPy\") and extra == \"standard\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/05/805df4850d9659efd69d00076269ae6adcb0e151d1922cff822ead2c432a/uvloop-0.15.2-cp37-cp37m-manylinux2010_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 36.6MB/s \n",
            "\u001b[?25hCollecting websockets==8.*; extra == \"standard\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/0b/3ebc752392a368af14dd24ee041683416ac6d2463eead94b311b11e41c82/websockets-8.1-cp37-cp37m-manylinux2010_x86_64.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.9MB/s \n",
            "\u001b[?25hCollecting httptools==0.1.*; (sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"PyPy\") and extra == \"standard\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/52/295101ea5a60f9bee805a3ca422863600ba5cac4e2778ac7bd56efab1231/httptools-0.1.1-cp37-cp37m-manylinux1_x86_64.whl (217kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 36.7MB/s \n",
            "\u001b[?25hCollecting watchgod>=0.6; extra == \"standard\"\n",
            "  Downloading https://files.pythonhosted.org/packages/57/35/9a8da3fb6681e6eba662b2d249eea58cebf575e392271efac3344c172c5f/watchgod-0.7-py3-none-any.whl\n",
            "Collecting aniso8601<=7,>=3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/a4/b4fcadbdab46c2ec2d2f6f8b4ab3f64fd0040789ac7f065eba82119cd602/aniso8601-7.0.0-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.0MB/s \n",
            "\u001b[?25hCollecting graphql-core<3,>=2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/71/d51beba3d8986fa6d8670ec7bcba989ad6e852d5ae99d95633e5dacc53e7/graphql_core-2.3.2-py2.py3-none-any.whl (252kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 36.3MB/s \n",
            "\u001b[?25hCollecting graphql-relay<3,>=2\n",
            "  Downloading https://files.pythonhosted.org/packages/94/48/6022ea2e89cb936c3b933a0409c6e29bf8a68c050fe87d97f98aff6e5e9e/graphql_relay-2.0.1-py3-none-any.whl\n",
            "Collecting dnspython>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/2d/ae9e172b4e5e72fa4b3cfc2517f38b602cc9ba31355f9669c502b4e9c458/dnspython-2.1.0-py3-none-any.whl (241kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 41.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from email_validator<2.0.0,>=1.1.1; extra == \"all\"->fastapi[all]) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0; extra == \"all\"->fastapi[all]) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0; extra == \"all\"->fastapi[all]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0; extra == \"all\"->fastapi[all]) (2020.12.5)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (7.6.3)\n",
            "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (5.0.5)\n",
            "Collecting ipykernel>=5.1.2; python_version >= \"3.4\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/95/3a670c8b2c2370bd8631c313f42e60983b3113ffec4035940592252bd6d5/ipykernel-5.5.0-py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 40.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators->streamlit) (4.4.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.11.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.6.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.0->streamlit) (2018.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->streamlit) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.11,>=3.6.0->streamlit) (54.0.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.4MB/s \n",
            "\u001b[?25hCollecting rx<2,>=1.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/0f/5ef4ac78e2a538cc1b054eb86285fe0bf7a5dbaeaac2c584757c300515e2/Rx-1.6.1-py2.py3-none-any.whl (179kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 34.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.3 in /usr/local/lib/python3.7/dist-packages (from graphql-core<3,>=2.1->graphene<3.0.0,>=2.1.8; extra == \"all\"->fastapi[all]) (2.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.0.0)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.1.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.3.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (5.3.5)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/d5/1e/6130925131f639b2acde0f7f18b73e33ce082ff2d90783c436b52040af5a/smmap-3.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (4.8.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.3.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (4.7.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (22.0.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.9.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.6.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.4.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.3.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
            "Building wheels for collected packages: pyngrok, python-multipart, blinker\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.0.3-cp37-none-any.whl size=18979 sha256=d36bcfe3c8d59356a54d3cd312a1926fc87c9b7e44d756441b2601c3f1461223\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/77/01/d23761888c52099d1817121dc1f28afbc1c7cbf3caac93b1ff\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-multipart: filename=python_multipart-0.0.5-cp37-none-any.whl size=31671 sha256=5b2e3491f8ad8caa1645694b459ce8f34252b85d6b6c36f20cc53bb40b5a45d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/e6/66/14a866a3cbd6a0cabfbef91f7edf40aa03595ef6c88d6d1be4\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for blinker: filename=blinker-1.4-cp37-none-any.whl size=13448 sha256=5c59edf148171b8b11d18e6fd49381ad5fd861d92c8404fb8b10ad3b2f3f6de5\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/a0/00/8690a57883956a301d91cf4ec999cc0b258b01e3f548f86e89\n",
            "Successfully built pyngrok python-multipart blinker\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.5.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pydantic, starlette, python-multipart, async-exit-stack, aiofiles, h11, python-dotenv, uvloop, pyyaml, websockets, httptools, watchgod, uvicorn, orjson, aniso8601, rx, graphql-core, graphql-relay, graphene, dnspython, email-validator, ujson, requests, fastapi, pyngrok, ipykernel, pydeck, validators, blinker, base58, smmap, gitdb, gitpython, watchdog, streamlit\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "Successfully installed aiofiles-0.5.0 aniso8601-7.0.0 async-exit-stack-1.0.1 base58-2.1.0 blinker-1.4 dnspython-2.1.0 email-validator-1.1.2 fastapi-0.63.0 gitdb-4.0.5 gitpython-3.1.14 graphene-2.1.8 graphql-core-2.3.2 graphql-relay-2.0.1 h11-0.12.0 httptools-0.1.1 ipykernel-5.5.0 orjson-3.5.0 pydantic-1.8.1 pydeck-0.6.1 pyngrok-5.0.3 python-dotenv-0.15.0 python-multipart-0.0.5 pyyaml-5.4.1 requests-2.25.1 rx-1.6.1 smmap-3.0.5 starlette-0.13.6 streamlit-0.77.0 ujson-3.2.0 uvicorn-0.13.4 uvloop-0.15.2 validators-0.18.2 watchdog-2.0.2 watchgod-0.7 websockets-8.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ipykernel"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ole4kY64LX50"
      },
      "source": [
        "%%writefile main.py\n",
        "\n",
        "from fastapi import FastAPI\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    return {\"message\": \"Hello World\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8N6cLqNJyMm"
      },
      "source": [
        "%%writefile main.py\n",
        "\n",
        "from typing import Optional\n",
        "\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class Indentity(BaseModel):\n",
        "    name: str\n",
        "    surname: Optional[str] = None\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    return {\"message\": \"Hello World\"}\n",
        "\n",
        "@app.post(\"/testing\")\n",
        "async def testing(id: Indentity):\n",
        "    if id.surname is None:\n",
        "      message = f\"Welcome to the API! My name is {id.name}\"\n",
        "    else: message = f\"Welcome to the API! My name is {id.name} {id.surname}\"\n",
        "    return {\"message\": message}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmAYFQ-SKCN_"
      },
      "source": [
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsEoRB6c_Jyr"
      },
      "source": [
        "! uvicorn main:app --port 8000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLQtYIS0kRF4"
      },
      "source": [
        "# ¡Manos a la obra!\n",
        "\n",
        "Ahora vamos a comenzar con el desarrollo de la API para inferencias online. Para cada petición que recibamos de predicción vamos a realizar tres pasos:\n",
        "\n",
        "1.   **Preprocesamiento**: en este primer paso extraeremos el dato a inferir de la petición y aplicaremos el preprocesado necesario\n",
        "2.   **Inferencia**: realizaremos la inferencia sobre nuestro modelo.\n",
        "3. **Postprocesado**: generaremos un JSON de respuesta con el resultado de la inferencia\n",
        "\n",
        "**INTRODUCIR DIAGRAMA DE LA PRÁCTICA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrxbT-7-pt9f"
      },
      "source": [
        "## Configuración de nuestro proyecto en GCP\n",
        "\n",
        "**Los siguientes pasos es obligatorio realizarlos para seguir con la práctica.**\n",
        "\n",
        "1.   Selecciona o crea un proyecto en GCP\n",
        "2.   Asegurate de que la facturación está activada para tu proyecto.\n",
        "3.   [Habilita la API de Google Cloud Storage](https://console.cloud.google.com/apis/library/storage-component.googleapis.com?q=storage).\n",
        "4. [Habilita la API de Google Cloud Registry](https://console.cloud.google.com/apis/library/containerregistry.googleapis.com?q=container).\n",
        "5. [Habilita la API de Google Cloud Run](https://console.cloud.google.com/apis/library/run.googleapis.com?q=cloud%20run).\n",
        "6. [Habilita la API de Google Cloud Build](https://console.cloud.google.com/apis/library/cloudbuild.googleapis.com?q=cloud%20build).\n",
        "7. [Habilita la API de App Engine Flexible Environment](https://console.cloud.google.com/apis/library/appengineflex.googleapis.com?q=app%20eng).\n",
        "8. [Habilita la API de App Engine Admin](https://console.cloud.google.com/apis/library/appengine.googleapis.com?q=app%20engine).\n",
        "9. Introduce tu ID de proyecto de GCP en la celda de abajo. Ejecuta la celda para asegurarnos de que el Cloud SDK usa el proyecto adecuado para todos los comandos en este notebook.\n",
        "\n",
        "**Nota**: Jupyter ejecuta las lineas con el prefijo `!` como comandos shell de consola, y puede usar variables de Python en los comandos añadiendoles el prefijo `$`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "4qxwBA4RM9Lu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27193e07-9163-4b99-85fc-e563aa68649d"
      },
      "source": [
        "PROJECT_ID = \"pre-launch-keepcoding\" #@param {type:\"string\"}\n",
        "! gcloud config set project $PROJECT_ID"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "W9i6oektpgld",
        "tags": [
          "skip"
        ]
      },
      "source": [
        "import sys\n",
        "\n",
        "# If you are running this notebook in Colab, run this cell and follow the\n",
        "# instructions to authenticate your GCP account. This provides access to your\n",
        "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
        "# requests.\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "  from google.colab import auth as google_auth\n",
        "  google_auth.authenticate_user()\n",
        "\n",
        "# If you are running this notebook locally, replace the string below with the\n",
        "# path to your service account key and run this cell to authenticate your GCP\n",
        "# account.\n",
        "else:\n",
        "  %env GOOGLE_APPLICATION_CREDENTIALS ''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azNFFNMgpKBr"
      },
      "source": [
        "## Creación bucket en Cloud Storage\n",
        "\n",
        "**Los siguientes pasos son obligatorios.**\n",
        "\n",
        "Cuando ejecutemos un job de entrenamiento usando el Cloud SDK, lo que hacemos es subir un paquete Python que contiene el código de entrenamiento a Google Cloud Storage. AI Platform ejecuta este paquete en el job.\n",
        "\n",
        "Establece el nombre del bucket a continuación. El nombre tiene que ser único para todos los bucket de GCP. También tenemos que establecer la variable `REGION`, la cual usaremos para todas las operaciones a lo largo del notebook. Asegurate de [elegir una región en la que Cloud AI Platform esté disponible](https://cloud.google.com/ml-engine/docs/tensorflow/regions)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "bTxmbDg1I0x1"
      },
      "source": [
        "BUCKET_NAME = \"twitter-sentiment-keepcoding-bucket\" #@param {type:\"string\"}\n",
        "REGION = \"europe-west1\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlQymziRrHqS"
      },
      "source": [
        "**Sólo si tu bucket aún no existe**: Ejecuta la siguiente celda para crear tu bucket en Cloud Storage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "160PRO3aJqLD"
      },
      "source": [
        "! gsutil mb -l $REGION gs://$BUCKET_NAME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiH1VHmqrVVE"
      },
      "source": [
        "Finalmente, validamos que tenemos acceso al bucket de Cloud Storage mirando sus contenidos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "OsB4T3sbSb2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7638615-68be-421c-b0d1-72b2cd80e5a4"
      },
      "source": [
        "! gsutil ls -al gs://$BUCKET_NAME"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                 gs://twitter-sentiment-keepcoding-bucket/models/\n",
            "                                 gs://twitter-sentiment-keepcoding-bucket/twitter-sentiment-batch/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnK-kOtZrjSv"
      },
      "source": [
        "## Descarga de la plantilla de código\n",
        "\n",
        "Ahora nos descargaremos la plantilla de código que vamos a ir rellenando para el desarrollo de la práctica y establecemos el directorio como directorio de trabajo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myt2V07Ds8sj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8af8a66b-6b20-4055-9809-8d256ebefd8f"
      },
      "source": [
        "# Clone the repository\n",
        "! git clone https://gitlab.keepcoding.io/despliegue-de-algoritmos-vi/twitter-sentiment-analysis-online.git\n",
        "\n",
        "# Set the working directory to the sample code directory\n",
        "%cd ./twitter-sentiment-analysis-online"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/twitter-sentiment-online\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIQBqjSqthMj"
      },
      "source": [
        "## Instalación de dependencias\n",
        "\n",
        "Ejecutamos la siguiente celda para instalar las dependencias de Python necesarias para entrenar el modelo localmente y preprocesar datos. \n",
        "\n",
        "Cuando ejecutemos el job de entrenamiento en AI Platform, las dependencias estarán instaladas en base a la [versión del runtime](https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list) elegido."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Wm5w1UrmVU7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf7c0486-a6da-4108-8a43-ee5e5df62e43"
      },
      "source": [
        "! pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting requests==2.25.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/fc/f91eac5a39a65f75a7adb58eac7fa78871ea9872283fb9c44e6545998134/requests-2.25.0-py2.py3-none-any.whl (61kB)\n",
            "\r\u001b[K     |█████▍                          | 10kB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 20kB 16.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 30kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 40kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 51kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.5MB/s \n",
            "\u001b[?25hCollecting uvicorn==0.12.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/cc/01cc4cb980dfcf04eb283b6497c7f280928a0b02c68c0f85b6901e7716ae/uvicorn-0.12.2-py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.6MB/s \n",
            "\u001b[?25hCollecting fastapi==0.61.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/0b/5df17eaadb7fe39dad349f484e551e802ce0581be672822f010c530d5e75/fastapi-0.61.2-py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (2.10.0)\n",
            "Collecting scikit-learn==0.23.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/cb/64623369f348e9bfb29ff898a57ac7c91ed4921f228e9726546614d63ccb/scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8MB 27.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.4.1)\n",
            "Collecting tensorflow==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/56/0dbdae2a3c527a119bec0d5cf441655fe030ce1daa6fa6b9542f7dbd8664/tensorflow-2.1.0-cp37-cp37m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |██████████████████████▉         | 301.5MB 1.5MB/s eta 0:01:22\u001b[31mERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 153, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 382, in run\n",
            "    resolver.resolve(requirement_set)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/legacy_resolve.py\", line 201, in resolve\n",
            "    self._resolve_one(requirement_set, req)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/legacy_resolve.py\", line 365, in _resolve_one\n",
            "    abstract_dist = self._get_abstract_dist_for(req_to_install)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/legacy_resolve.py\", line 313, in _get_abstract_dist_for\n",
            "    req, self.session, self.finder, self.require_hashes\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/prepare.py\", line 194, in prepare_linked_requirement\n",
            "    progress_bar=self.progress_bar\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/download.py\", line 465, in unpack_url\n",
            "    progress_bar=progress_bar\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/download.py\", line 316, in unpack_http_url\n",
            "    progress_bar)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/download.py\", line 551, in _download_http_url\n",
            "    _download_url(resp, link, content_file, hashes, progress_bar)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/download.py\", line 253, in _download_url\n",
            "    hashes.check_against_chunks(downloaded_chunks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/hashes.py\", line 80, in check_against_chunks\n",
            "    for chunk in chunks:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/download.py\", line 223, in written_chunks\n",
            "    for chunk in chunks:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/ui.py\", line 162, in iter\n",
            "    self.next(n)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/progress/__init__.py\", line 120, in next\n",
            "    self.update()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/progress/bar.py\", line 83, in update\n",
            "    self.writeln(line)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/progress/__init__.py\", line 101, in writeln\n",
            "    self.clearln()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/progress/__init__.py\", line 90, in clearln\n",
            "    print('\\r\\x1b[K', end='', file=self.file)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/ui.py\", line 118, in handle_sigint\n",
            "    self.finish()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/ui.py\", line 108, in finish\n",
            "    super(InterruptibleMixin, self).finish()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/progress/__init__.py\", line 107, in finish\n",
            "    print(file=self.file)\n",
            "RuntimeError: reentrant call inside <_io.BufferedWriter name='<stdout>'>\u001b[0m\n",
            "\u001b[K"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjcPYWRE4u45"
      },
      "source": [
        "# Nos aseguramos que nuestras variables de entorno no hayan desaparecido al reiniciar el kernel\n",
        "\n",
        "print(f\"Project: {PROJECT_ID}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EI4ez_cbGDLb"
      },
      "source": [
        "# Desarrollo del microservicio de inferencia\n",
        "\n",
        "En la plantilla de código se proporciona una estructura de proyecto genérica para cualquier desarrollo de una API de inferencia online lista para ser usada de manera productiva."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpAFp9VUkQLI"
      },
      "source": [
        "El proyecto tiene la siguiente estructura:\n",
        "\n",
        "``` bash\n",
        "twitter-sentiment-online/\n",
        "├── app/\n",
        "│   ├── __init__.py\n",
        "│   ├── api/\n",
        "│   │   ├── __init__.py\n",
        "│   │   └── routes/\n",
        "│   │       ├── __init__.py\n",
        "│   │       ├── heartbeat.py\n",
        "│   │       ├── prediction.py\n",
        "│   │       └── router.py\n",
        "│   ├── core/\n",
        "│   │   ├── __init__.py\n",
        "│   │   ├── config.py\n",
        "│   │   ├── enums.py\n",
        "│   │   ├── event_handlers.py\n",
        "│   │   └── messages.py\n",
        "│   ├── main.py\n",
        "│   ├── models/\n",
        "│   │   ├── __init__.py\n",
        "│   │   ├── heartbeat.py\n",
        "│   │   ├── payload.py\n",
        "│   │   └── prediction.py\n",
        "│   └── services/\n",
        "│       ├── __init__.py\n",
        "│       └── models.py\n",
        "├── Dockerfile\n",
        "├── README.md\n",
        "└── requirements.txt\n",
        "```\n",
        "\n",
        "En esta estructura distinguimos los siguientes componentes:\n",
        "\n",
        "* **Dockerfile**: aquí definimos la imagen base que usaremos y como empaquetamos el proyecto.\n",
        "* **requirements.txt**: especificación de dependencias a instalar en el microservicio.\n",
        "* **app**: aplicación de inferencia online en FastAPI.\n",
        "    * **main.py**: punto de entrada para la ejecución de la aplicación.\n",
        "    * **models**: en este encontramos la definición de los esquemas que usaremos dentro de la aplicación.\n",
        "    * **services**: en este módulo incluiremos la implementación de nuestra clase de inferencia.\n",
        "    * **api/routes**: módulo en el que definiremos los diferentes endpoints que tendrá la API.\n",
        "    * **api/core**: módulo donde estarán funcionalidades comunes al servicio y configuraciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FUa3ZksyWHY"
      },
      "source": [
        "%cd /content/twitter-sentiment-analysis-online/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn9xsgx4u5xP"
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"DEFAULT_MODEL_PATH\"] = \"/content/twitter-sentiment-analysis-online/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A47h9iMuoiT"
      },
      "source": [
        "! gsutil -m cp \\\n",
        "  \"gs://$BUCKET_NAME/twitter-sentiment-batch/data/model/model.h5\" \\\n",
        "  \"gs://$BUCKET_NAME/twitter-sentiment-batch/data/model/tokenizer.pkl\" \\\n",
        "  ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwFsPWPivkaA"
      },
      "source": [
        "Para poder probar el correcto funcionamiento del servicio en local:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncn9K4uJtsBM"
      },
      "source": [
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFeSh7rcuG7L"
      },
      "source": [
        "! uvicorn app.main:app --port 8000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIvEgcv_bxtK"
      },
      "source": [
        "## Creando la interfaz usando Streamlit\n",
        "\n",
        "[Streamlit](https://www.streamlit.io/) es un framework para la creación de Webapps orientado a datos e Inteligencia Artificial basado en Python.\n",
        "\n",
        "En este caso vamos a desarrollar un pequeño frontal para poder invocar nuestro recién desarrollado servicio de inferencia para realizar predicciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGBBJ8wvso_Y"
      },
      "source": [
        "%mkdir /content/prediction-front"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyZNJWwLpvp3"
      },
      "source": [
        "%cd /content/prediction-front"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_Saa9oodCT0"
      },
      "source": [
        "%%writefile front.py\n",
        "\n",
        "import requests\n",
        "import validators\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "st.title(\"Sentiment Analysis Predictions\")\n",
        "\n",
        "st.markdown(\n",
        "    \"Welcome! With this app you can predict the sentiment of a given text using Deep Learning :smile:\"\n",
        ")\n",
        "\n",
        "st.write(\"Fist, paste below the predictor server URL: \")\n",
        "\n",
        "server_url = st.text_input(\"Server URL\", value=\"\")\n",
        "\n",
        "if server_url != \"\":\n",
        "    st.write(f\"Server URL: {server_url}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtWgH2iZm5Hj"
      },
      "source": [
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8501)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYfVS1UNm6HY"
      },
      "source": [
        "! streamlit run front.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrySQisyGJKL"
      },
      "source": [
        "# Despliegue en GCP de la aplicación\n",
        "\n",
        "Ahora que ya tenemos nuestro servicio de inferencia online funcionando, estamos listos para desplegar a escala para que soporte miles de peticiones de manera concurrente, para ello utilizaremos el servicio de GCP Cloud Run.\n",
        "\n",
        "Cloud Run es un servicio Serverless (o sin servidor). Serveless nos facilita la puesta en producción de aplicaciones pues, en este caso GCP, se encarga de gestionar la infraestructura y recursos desplegados para nuestra aplicación en base a la carga que tenga esta misma a lo largo del tiempo. \n",
        "\n",
        "Esta práctica nos permita escalar de manera casi infinita, desde dar servicio desde tan solo a decenas de usuarios como a millones de manera concurrente sin tener que realizar ningún ajuste.\n",
        "\n",
        "Las aplicaciones Serverless son una alternativa a los microservicios y los monolitos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9VgEtyHvDQa"
      },
      "source": [
        "## Creando una aplicacion Serverless\n",
        "\n",
        "Para crear nuestra aplicación serverless tan solo nos tenemos que preocupar de que nuestro código funciona y empaquetar todo en una imagen Docker que, finalmente, será lo que despleguemos Cloud Run.\n",
        "\n",
        "Para crear esta imagen, dado que estamos en un entorno de Google Colab no podemos usar Docker, haremos uso del servicio Cloud Build en GCP, que se encargará de generarnos la imagen con nuestro Dockerfile de la aplicación y finalmente la guardará en el Google Container Registry, donde se almacenan las imágenes Docker."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU1Fl1SX3IU5"
      },
      "source": [
        "%cd /content/twitter-sentiment-analysis-online/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRhq-d_E7-CY"
      },
      "source": [
        "! gcloud builds submit --tag gcr.io/$PROJECT_ID/sentiment-analysis-server"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bJFhmAjEvQx"
      },
      "source": [
        "Finalmente, procederemos a desplegar la imagen docker en el servicio de GCP Cloud Run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oZ75Cy498tg"
      },
      "source": [
        "## Probando nuestra aplicación desplegada\n",
        "\n",
        "Una vez desplegado nuestra aplicación serverless de inferencia online... ¡Podemos usarla desde cualquier lugar del planeta! Tanto si es un usuario como si son millones. Para hacer un ejemplo de petición a nuestro modelo desplegado, podemos hacer lo siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC0honui-W23"
      },
      "source": [
        "! curl -X POST \"https://predict-service-p26tpbhusq-uc.a.run.app/api/model/predict\" -H  \"accept: application/json\" -H  \"Content-Type: application/json\" -d \"{\\\"text\\\":\\\"i hate\\\"}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I0S3x16qMsi"
      },
      "source": [
        "## Despliegue de la interfaz\n",
        "\n",
        "Para desplegar la interfaz de nuestra aplicación usaremos App Engine. Lo único que necesitaremos será un Dockerfile con el cual construiremos una imagen que será la que desplegaremos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXA0deb8qniC"
      },
      "source": [
        "%cd /content/prediction-front"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsQzvK5uq1n8"
      },
      "source": [
        "%%writefile requirements.txt\n",
        "\n",
        "requests\n",
        "validators\n",
        "pandas\n",
        "streamlit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mDwghVCqKxi"
      },
      "source": [
        "%%writefile Dockerfile\n",
        "\n",
        "FROM python:3.7.8-slim\n",
        "\n",
        "# remember to expose the port your app'll be exposed on.\n",
        "EXPOSE 8080\n",
        "\n",
        "RUN pip install -U pip\n",
        "\n",
        "COPY requirements.txt app/requirements.txt\n",
        "RUN pip install -r app/requirements.txt\n",
        "\n",
        "# copy into a directory of its own (so it isn't in the toplevel dir)\n",
        "COPY front.py /app/front.py\n",
        "WORKDIR /app\n",
        "\n",
        "# run it!\n",
        "ENTRYPOINT [\"streamlit\", \"run\", \"front.py\", \"--server.port=8080\", \"--server.address=0.0.0.0\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tN4_dLNrr6H8"
      },
      "source": [
        "%%writefile app.yaml\n",
        "\n",
        "runtime: custom\n",
        "env: flex\n",
        "# service: sentiment-analysis-front"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3dMczj7rPuE"
      },
      "source": [
        "! gcloud app deploy app.yaml"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}